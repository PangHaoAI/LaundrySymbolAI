{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LaundrySymbolAITraining_master.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szut-thiel/LaundrySymbolAI/blob/master/LaundrySymbolAITraining_2020_01_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afYZHnF-sFGn",
        "colab_type": "text"
      },
      "source": [
        "### **Installing Modules on Notebook**\n",
        "All used modules will be installed and imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd8CpjdBrls_",
        "colab_type": "code",
        "outputId": "d8115d9c-d1f9-4fd9-b34b-1c5fc9c36cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "# installing modules for tensorflow\n",
        "!pip install tensorflow==2.0 mnist pillow\n",
        "\n",
        "# installing modules for computer vision\n",
        "!pip install svglib\n",
        "!pip install reportlab\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np  # used to prepare data for tensorflow\n",
        "import matplotlib.pyplot as plt  # used to plot images for debugging\n",
        "import mnist  # TODO: remove after substitution of mnist Sequence class\n",
        "\n",
        "import os  # used for actions on filesystem \n",
        "import random  # used for splitting trainings set\n",
        "import math  # used for splitting trainings set\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (6.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.17.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.9.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.10.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Requirement already satisfied: svglib in /usr/local/lib/python3.6/dist-packages (0.9.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from svglib) (4.2.6)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.6/dist-packages (from svglib) (3.5.34)\n",
            "Requirement already satisfied: cssselect2>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from svglib) (0.2.2)\n",
            "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from svglib) (1.0.2)\n",
            "Requirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from reportlab->svglib) (6.2.2)\n",
            "Requirement already satisfied: webencodings>=0.4 in /usr/local/lib/python3.6/dist-packages (from tinycss2>=0.6.0->svglib) (0.5.1)\n",
            "Requirement already satisfied: setuptools>=39.2.0 in /usr/local/lib/python3.6/dist-packages (from tinycss2>=0.6.0->svglib) (42.0.2)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.6/dist-packages (3.5.34)\n",
            "Requirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from reportlab) (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9USt46-4c3M",
        "colab_type": "text"
      },
      "source": [
        "### **Preparing Trainings Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krcZwBxF4ttd",
        "colab_type": "code",
        "outputId": "f39b4d8b-864d-4bbc-e716-1dd8cb3a8564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Before launching the preparation of trainings data, a zipped directory named\n",
        "# raw_images_lite.zip including the directory raw_images_lite with inner\n",
        "# directories of all categories with images and license file has to uploaded to\n",
        "# the github repository.\n",
        "\n",
        "# updating set of images by deleting old set, downloading and unzipping new set\n",
        "!rm -rf raw_images_lite training_lite\n",
        "!wget https://raw.github.com/szut-thiel/LaundrySymbolAI/master/raw_images_lite.zip \n",
        "!unzip -q raw_images_lite.zip\n",
        "!rm -rf raw_images_lite.zip training.zip\n",
        "\n",
        "import shutil\n",
        "import errno\n",
        "import os\n",
        "import cv2\n",
        "import numpy\n",
        "from svglib.svglib import svg2rlg\n",
        "from reportlab.graphics import renderPM\n",
        "\n",
        "\n",
        "SOURCE = \"raw_images_lite\"\n",
        "TRAINING_IMAGES = \"training_lite\"\n",
        "IMAGE_WIDTH = 32\n",
        "NUMBER_OF_ORIENTATIONS = 72\n",
        "\n",
        "# preparing trainings data\n",
        "def prepare_training(source, target):\n",
        "  # if trainings data already exist, remove them before calculating new one\n",
        "  if os.path.exists(target):\n",
        "    shutil.rmtree(target)\n",
        "\n",
        "  # copying downloaded raw images to the new training directory\n",
        "  try:\n",
        "    shutil.copytree(source, target)\n",
        "  except OSError as error:\n",
        "    if error.errno == errno.ENOTDIR:\n",
        "      shutil.copy(source, target)\n",
        "    else:\n",
        "      raise\n",
        "\n",
        "  # preparing all raw images for training\n",
        "  for path, directories, files in os.walk(target):\n",
        "    for directory in directories:\n",
        "      print(directory)\n",
        "      prepare_category(path, directory)\n",
        "\n",
        "\n",
        "# preparing all images of one category\n",
        "def prepare_category(path, category):\n",
        "  index = 0\n",
        "  for path, directories, files in os.walk(os.path.join(path, category)):\n",
        "    for file in files:\n",
        "      prepare_image(os.path.join(path, file), category, index)\n",
        "      index += 1\n",
        "\n",
        "\n",
        "# preparing one image\n",
        "def prepare_image(path, category, index):\n",
        "  try:\n",
        "    png_path = path\n",
        "    print(\"path: {} category: {} index: {}\".format(path, category, index))\n",
        "\n",
        "    # converting svg images to png images\n",
        "    if path.endswith(\".svg\"):\n",
        "      png_path = \"{}png\".format(path[:-3])\n",
        "      svg = svg2rlg(path)\n",
        "      renderPM.drawToFile(svg, png_path, fmt=\"PNG\")\n",
        "      os.remove(path)\n",
        "\n",
        "    # loading png image\n",
        "    image = load_image(png_path)\n",
        "    \n",
        "    # converting image to grayscale image\n",
        "    image = grayscale_image(image)\n",
        "\n",
        "    # extending image to square\n",
        "    image = square_image(image)\n",
        "\n",
        "    # scaling image\n",
        "    image = scale_image(image, IMAGE_WIDTH, IMAGE_WIDTH)\n",
        "\n",
        "    # rotating image\n",
        "    for angle in range(0, 360, 360 // NUMBER_OF_ORIENTATIONS):\n",
        "      # thresholded_image = threshold_image(image) # FIXME: remove?\n",
        "      rotated_image = rotate_image(image, angle)\n",
        "\n",
        "      prepared_path = os.path.join(os.path.dirname(path),\n",
        "                                   \"{}.{}.a{:03d}.png\".format(category, index, angle))\n",
        "\n",
        "      # prepared_path = \"{}.a{:03d}.png\".format(path[:-4], angle)\n",
        "      save_image(rotated_image, prepared_path)\n",
        "    \n",
        "    # deleting raw image\n",
        "    os.remove(png_path)\n",
        "\n",
        "  except ValueError as error:\n",
        "    print(error)\n",
        "\n",
        "\n",
        "# convert rgb images to grayscale images\n",
        "def grayscale_image(image):\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "# extending images to squared resolution\n",
        "def square_image(image):\n",
        "  w = max(image.shape[0], image.shape[1])\n",
        "  y = (w - image.shape[0]) // 2\n",
        "  x = (w - image.shape[1]) // 2\n",
        "  return cv2.copyMakeBorder(image, y, y, x, x, cv2.BORDER_CONSTANT,\n",
        "                            value=[255, 255, 255])\n",
        "\n",
        "\n",
        "# scaling image\n",
        "def scale_image(image, width, height):\n",
        "  return cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "# rotating image around center\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(numpy.array(image.shape[1::-1]) / 2)\n",
        "  rotation_matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  return cv2.warpAffine(image, rotation_matrix, image.shape[1::-1],\n",
        "                        flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255))\n",
        "  \n",
        "\n",
        "# converting image to black and white image\n",
        "def threshold_image(image, threshold=0.5):\n",
        "  _, threshed = cv2.threshold(image, int(255 * threshold), 255, cv2.THRESH_BINARY)\n",
        "  return threshed\n",
        "\n",
        "\n",
        "# inverting image\n",
        "def invert_image(image):\n",
        "  return cv2.bitwise_not(image)\n",
        "\n",
        "\n",
        "# loading image from file\n",
        "def load_image(path):\n",
        "  return cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "\n",
        "# saving image to file\n",
        "def save_image(image, path):\n",
        "  cv2.imwrite(path, image)\n",
        "\n",
        "\n",
        "prepare_training(SOURCE, TRAINING_IMAGES)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-16 15:22:50--  https://raw.github.com/szut-thiel/LaundrySymbolAI/master/raw_images_lite.zip\n",
            "Resolving raw.github.com (raw.github.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.github.com (raw.github.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/szut-thiel/LaundrySymbolAI/master/raw_images_lite.zip [following]\n",
            "--2020-01-16 15:22:50--  https://raw.githubusercontent.com/szut-thiel/LaundrySymbolAI/master/raw_images_lite.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95500 (93K) [application/zip]\n",
            "Saving to: ‘raw_images_lite.zip’\n",
            "\n",
            "\rraw_images_lite.zip   0%[                    ]       0  --.-KB/s               \rraw_images_lite.zip 100%[===================>]  93.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-01-16 15:22:50 (3.11 MB/s) - ‘raw_images_lite.zip’ saved [95500/95500]\n",
            "\n",
            "bleaching_dont\n",
            "path: training_lite/bleaching_dont/Nicht_bleichen_v2.svg category: bleaching_dont index: 0\n",
            "path: training_lite/bleaching_dont/LAUNDRY.cropped02-02.jpg category: bleaching_dont index: 1\n",
            "path: training_lite/bleaching_dont/CARE-SYMBOLS_BLEACHING_DONOT-BLEACH.png category: bleaching_dont index: 2\n",
            "path: training_lite/bleaching_dont/Nicht_bleichen.svg category: bleaching_dont index: 3\n",
            "washing_60\n",
            "path: training_lite/washing_60/CARE-SYMBOLS_WASHING_NORMAL-60.png category: washing_60 index: 0\n",
            "path: training_lite/washing_60/LAUNDRY.cropped01-03.jpg category: washing_60 index: 1\n",
            "path: training_lite/washing_60/Waschen_60.svg category: washing_60 index: 2\n",
            "path: training_lite/washing_60/LAUNDRY.cropped01-02.jpg category: washing_60 index: 3\n",
            "dry_cleaning\n",
            "path: training_lite/dry_cleaning/Professionelle_reinigung_(A).svg category: dry_cleaning index: 0\n",
            "path: training_lite/dry_cleaning/Professionelle_reinigung.svg category: dry_cleaning index: 1\n",
            "path: training_lite/dry_cleaning/LAUNDRY.cropped05-01.jpg category: dry_cleaning index: 2\n",
            "path: training_lite/dry_cleaning/LAUNDRY.cropped05-00.jpg category: dry_cleaning index: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifNpS18mwXb4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3iZtTfv0f6l",
        "colab_type": "text"
      },
      "source": [
        "### **Loading Training Set to Numpy-Array FIXME: substitute by preparation pipeline: opencv and numpy at once**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mG0lGdS0pJj",
        "colab_type": "code",
        "outputId": "ab94b4f1-11f0-4c30-d13f-64099da41933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "TRAINING_PERCENTAGE = 0.7 # between 0 and 1\n",
        "\n",
        "\n",
        "# loading image data of file and returning numpy array\n",
        "def load_image_data(path):\n",
        "  image = Image.open(path)\n",
        "  return np.array(image.getdata())\n",
        "\n",
        "\n",
        "def load_image_data_of_category(path, category):\n",
        "  image_data_of_category = []\n",
        "  for path, directories, files in os.walk(os.path.join(path, category)):\n",
        "    for file in files:\n",
        "      image_data = load_image_data(os.path.join(path, file))\n",
        "      image_data_of_category.append(image_data)\n",
        "  return image_data_of_category\n",
        "\n",
        "\n",
        "def load_training_data(path):\n",
        "  categories = []\n",
        "  training_image_data = []\n",
        "  training_label = []\n",
        "  testing_image_data = []\n",
        "  testing_label = []\n",
        "\n",
        "  for path, directories, files in os.walk(path):\n",
        "    for category in directories:\n",
        "      if category not in categories:\n",
        "        categories.append(category)\n",
        "\n",
        "      image_data = np.array(load_image_data_of_category(path, category))\n",
        "      label = [categories.index(category)] * len(image_data)\n",
        "      image_data = image_data.reshape(len(image_data), 32, 32)\n",
        "      image_data = np.expand_dims(image_data, axis=3)\n",
        "      \n",
        "      print(image_data.shape)\n",
        "      print(image_data[0].shape)\n",
        "      \n",
        "      # shuffling lists\n",
        "      #zipped_list = list(zip(image_data, label))\n",
        "      #random.shuffle(zipped_list)\n",
        "      #(image_data, label) = zip(*zipped_list)\n",
        "      #label = list(label)\n",
        "\n",
        "      #image_data = np.array(image_data)\n",
        "      #image_data = image_data.reshape(len(image_data), 32, 32)\n",
        "\n",
        "      # splitting shuffled tuples and adding them to lists\n",
        "      split_index = math.floor(len(image_data) * TRAINING_PERCENTAGE)\n",
        "\n",
        "      training_image_data.append image_data[:split_index]))\n",
        "      training_label += label[:split_index]\n",
        "\n",
        "      testing_image_data.append(image_data[split_index:])\n",
        "      testing_label += label[split_index:]\n",
        "\n",
        "  return (categories,\n",
        "          training_image_data, training_label,\n",
        "          testing_image_data, testing_label)\n",
        "  \n",
        "\n",
        "(categories,\n",
        " training_image_data, training_label,\n",
        " testing_image_data, testing_label) = load_training_data(TRAINING_IMAGES)\n",
        "\n",
        "print(training_image_data)\n",
        "print(testing_image_data.shape)\n",
        "\n",
        "print(training_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 32, 32, 1)\n",
            "(32, 32, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-726ba1e9676b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m (categories,\n\u001b[1;32m     63\u001b[0m  \u001b[0mtraining_image_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m  testing_image_data, testing_label) = load_training_data(TRAINING_IMAGES)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_image_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-140-726ba1e9676b>\u001b[0m in \u001b[0;36mload_training_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0msplit_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTRAINING_PERCENTAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_image_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mtraining_label\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 4 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYBAa0rlTJNC",
        "colab_type": "code",
        "outputId": "6d5db10a-a2fc-4900-d246-6a23d63f86f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbwWu5HebtnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usns4G4EdwkW",
        "colab_type": "code",
        "outputId": "8e0ab2c4-4ae9-48ef-ff46-66d22c9ca945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "check_index = random.randint(0, len(training_image_data) - 1)\n",
        "print(\"check: {}\".format(categories[training_label[check_index]]))\n",
        "image = np.resize(training_image_data[check_index], (32, 32))\n",
        "_ = plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check: dry_cleaning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQax6xg7dwZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qg2H9resntx",
        "colab_type": "text"
      },
      "source": [
        "*italicized text*### **import dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG4g2_9ws-NR",
        "colab_type": "code",
        "outputId": "754a2f88-4d3f-4945-99d6-67961f33cc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "kernel_size = 8  # was 4\n",
        "\n",
        "model.add(layers.Input(shape=(32, 32, 1)))\n",
        "model.add(layers.Conv2D(6, (kernel_size, kernel_size), activation=tf.nn.relu))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(9, (kernel_size, kernel_size), activation=tf.nn.relu))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Conv2D(12, (kernel_size, kernel_size), activation=tf.nn.relu))\n",
        "model.add(layers.MaxPooling2D((2, 2), (2, 2)))\n",
        "model.add(layers.Dense(20, activation=tf.nn.relu))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(58, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"mae\", \"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 25, 25, 6)         390       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 25, 25, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 9)         3465      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 18, 18, 9)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 12)        6924      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 12)          0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5, 5, 20)          260       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 58)                29058     \n",
            "=================================================================\n",
            "Total params: 40,097\n",
            "Trainable params: 40,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDxk40Yqd3rh",
        "colab_type": "text"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uTyHFLnd8ac",
        "colab_type": "code",
        "outputId": "49bf6117-5f84-4912-e3df-56d8a79f300a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def check_parameter(parameter):\n",
        "  print(\"type: {}\".format(str(type(parameter))))\n",
        "  if type(parameter) == tuple or type(parameter) == list:\n",
        "    print(\"   \", end=\"\")\n",
        "    check_parameter(parameter[0])\n",
        "\n",
        "\n",
        "check_parameter(training_image_data)\n",
        "check_parameter(training_label)\n",
        "check_parameter(testing_image_data)\n",
        "check_parameter(testing_label)\n",
        "\n",
        "history = model.fit(training_image_data, np.asarray(training_label), epochs=100, batch_size=100, \n",
        "                    validation_data=(testing_image_data, np.asarray(testing_label)))\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation Loss\")\n",
        "plt.title(\"Training Evaluation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type: <class 'numpy.ndarray'>\n",
            "type: <class 'list'>\n",
            "   type: <class 'int'>\n",
            "type: <class 'numpy.ndarray'>\n",
            "type: <class 'list'>\n",
            "   type: <class 'int'>\n",
            "[[[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]]\n",
            "\n",
            "\n",
            " [[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[168]\n",
            "   [168]\n",
            "   [168]\n",
            "   ...\n",
            "   [167]\n",
            "   [169]\n",
            "   [255]]\n",
            "\n",
            "  [[217]\n",
            "   [203]\n",
            "   [188]\n",
            "   ...\n",
            "   [168]\n",
            "   [186]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [168]\n",
            "   [203]\n",
            "   [255]]]\n",
            "\n",
            "\n",
            " [[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]]\n",
            "\n",
            "\n",
            " [[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]]\n",
            "\n",
            "\n",
            " [[[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]\n",
            "\n",
            "  [[255]\n",
            "   [255]\n",
            "   [255]\n",
            "   ...\n",
            "   [255]\n",
            "   [255]\n",
            "   [255]]]]\n",
            "Train on 201 samples, validate on 87 samples\n",
            "Epoch 1/100\n",
            "201/201 [==============================] - 1s 7ms/sample - loss: 115.8433 - mae: 1.9828 - accuracy: 0.0000e+00 - val_loss: 7.5038 - val_mae: 1.9828 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 12.8952 - mae: 1.9828 - accuracy: 0.0299 - val_loss: 2.0431 - val_mae: 1.9828 - val_accuracy: 0.2874\n",
            "Epoch 3/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.2559 - mae: 1.9828 - accuracy: 0.6567 - val_loss: 1.6728 - val_mae: 1.9828 - val_accuracy: 0.6437\n",
            "Epoch 4/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.3299 - mae: 1.9828 - accuracy: 0.9254 - val_loss: 1.2586 - val_mae: 1.9828 - val_accuracy: 0.9310\n",
            "Epoch 5/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.1625 - mae: 1.9828 - accuracy: 0.9851 - val_loss: 0.9446 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0776 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.6814 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0502 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.4611 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0306 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.2944 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0127 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.1503 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0045 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0685 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 0.0021 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0290 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.3554e-04 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0124 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5161e-04 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0059 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 7.4092e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0030 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.9728e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0017 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8983e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 0.0010 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1703e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 6.9948e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8156e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 5.0678e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.7267e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 3.9261e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 3.8620e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 3.2173e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.8835e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 2.7546e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 3.5898e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 2.4416e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 3.1331e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 2.2238e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.5051e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 2.0692e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 3.2006e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.9559e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.6867e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.8698e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.3313e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.8051e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.2870e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.7537e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 9.5781e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.7102e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 7.7672e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.6709e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.5852e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.6390e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.5486e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.6106e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.3924e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.5850e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 5.4868e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.5599e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.4744e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.5400e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.6117e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.5226e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5574e-05 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.4981e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1761e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.4643e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5177e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.4375e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8385e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.4160e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.3492e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3983e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.6730e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3831e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.2674e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3698e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0652e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3578e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.5418e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3442e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5823e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3319e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0426e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3214e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0764e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3116e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.2899e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.3026e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.6615e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2926e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0539e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2831e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 8.5640e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2732e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.9980e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2633e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.9093e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2545e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.6623e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2455e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.1015e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2348e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 8.5996e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2245e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.8959e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2128e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1701e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.2023e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.1516e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1914e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 3.5776e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1798e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5271e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1660e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1043e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1497e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 9.9636e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1357e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0586e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1229e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.0940e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.1016e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.2850e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0821e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8379e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0653e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1933e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0505e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.6784e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0361e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.9344e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0246e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1090e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0144e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.6265e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 1.0029e-04 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.5965e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.9037e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.6662e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.7958e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.2846e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.6976e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 7.1940e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.6110e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1512e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.5322e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.4482e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.4508e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.1101e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.3670e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 6.3222e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.2935e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 9.4773e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.2231e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 5.0115e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.1623e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 8.0777e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.1045e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.3243e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 9.0412e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.7861e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.9845e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 9.1511e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.9302e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8254e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.8677e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.4194e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.8013e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1945e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.7256e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 9.3704e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.6564e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.1298e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.5870e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.0187e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.5025e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 4.6260e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.4313e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0432e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.3596e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.8438e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.2753e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 2.1338e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.1772e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.3409e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 8.0853e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 1.0420e-06 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 7.9959e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "201/201 [==============================] - 0s 2ms/sample - loss: 8.2555e-07 - mae: 1.9828 - accuracy: 1.0000 - val_loss: 7.9107e-05 - val_mae: 1.9828 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3wV9Z3/8debkBi5yE28IFhotXIH\n0yyVWioU16K1opb1Uu/a0p+P/qrW6kq73eq62tquD7y1tbVVq7uKWtTiesF1EapWqgJVFLGFH2IJ\nIgSsyEXFwOf3xwxjhCQkISfnJOf9fDzOIzNz5vKZTB55n/nOnO8oIjAzMwPokO8CzMyscDgUzMws\n41AwM7OMQ8HMzDIOBTMzyzgUzMws41CwNk1SiaSNkg5syXkLhaSvS5qTo3V/UtLGXKzb2i6HgrWq\n9J/y9tc2Se/VGj+tqeuLiK0R0SUi/taS8zaVpKskfbjD/q1t6e3sDklVksZuH4+IZRHRJY8lWQHq\nmO8CrLjU/ickaTnw9Yj43/rml9QxImpao7YWcFdEnJ3vIsx2h88UrKCkn7jvlTRN0gbgdEmjJf1J\n0juSVkm6UVJpOn9HSSGpfzr+X+n7j0naIGmupAFNnTd9/2hJf5W0XtJNkv4o6exm7NOvJV2zw7RH\nJF2QDv9A0rK0hkWSjqtnPQdJih2mPbO9JkkHS5ot6W1JayX9p6Ru6XvTgD7AY+lZzMU7rk9SX0kP\np8svkXTuDsdlWvo72yDpFUkVTf1dWOFzKFghOgG4G+gG3AvUABcCewOHAxOAbzaw/NeAfwV6An8D\n/r2p80raB7gPuDTd7uvAqGbuzzTgFElK190L+CLJvgH8lWS/ugFXA3dL2rcZ2xFwFbAfMBj4JMm+\nERGnAm8CR6dNaFPrWP5ekv3sA5wM/FTSEbXePx74T6A78BhwYzNqtALnULBC9ExE/HdEbIuI9yLi\nhYh4LiJqImIZcAtwRAPLT4+IeRHxIXAXMLIZ8x4LvBgRM9L3rgN2dY3ga+nZzPbXE+n0OUApMDod\nPwl4OiJWA0TEfRGxKt3fu4HlQOUutrWTiPhrRMyKiC0RsSatuaHfUyY9QxoFTImI9yNiAXA7cEat\n2f4QEY9HxFaScGjo92ptlEPBCtGK2iOSBqbNLW9Jehe4kuTTe33eqjW8GWjoYmp98/apXUckPUdW\n7aLuuyOie63XP6bLbiP5FH5qOt/XSAIIAElnS3ppe5gAA2l4/+okaT9J90lamf6eftuE9fQB1kbE\nplrT3gAOqDW+4++qc1NrtMLnULBCtGPXvb8CXgEOioi9gB+SNJXk0iqg7/aRtOnngPpn36VpwD+l\nn8grgAfS9X4SuBk4H+gVEd2B16h7/zaly3SqNW2/WsM/AT4AhqW/p7N3WE9DXSK/CewtqfY/+gOB\nlbvcM2tXHArWFnQF1gObJA2i4esJLeVhoELSVyR1JLmm0bu5K4uIF4B3SZq+Ho2IDelbXUj+WVeT\nZM83SM4U6vJW+jo9/c7FZOATtd7vShIc6yX1Ay7ZYfnVJNcZ6qrvdWAe8CNJe0gaCZwD/FfT9tTa\nOoeCtQXfBc4CNpCcNdzb8Oy7L23vPxmYCqwDPgX8meSTeH1O2+F7ChvTi8rbTQOOJLmIvn07C4Gb\ngOdJzk4OAZ6rp6YAvgF8n+T6xkE7zHs5yXWB9cBDwP07rOJHwL+lzVQX1bGJk4GDSYJnOvD9iJjT\nwP5aOyQ/ZMds1ySVkDSxTIqIp/Ndj1mu+EzBrB6SJkjqLmkPkls7PyT5RG/WbjkUzOr3eWAZSXv/\nl4ATIqKh5iOzNs/NR2ZmlvGZgpmZZXLWIZ6k20i+FbomIoam0/4D+AqwBfh/wDkR8U763veA84Ct\nwAUR8fiutrH33ntH//79c7MDZmbt1Pz589dGRJ23WOes+UjSF4CNwJ21QuEo4MmIqJH0E4CIuEzS\nYJLb9UaRfLPyf4FPp1+nr1dlZWXMmzcvJ/WbmbVXkuZHRJ1dqeSs+SgingLe3mHa/9TqBvlPfPSN\n0YnAPRHxQfolmqU0v/MxMzNrpnxeUziXpKdFSLoPqN3fTRX1dCkgabKkeZLmVVdX57hEM7PikpdQ\nkPQvJN0h37WreXcUEbdERGVEVPbu3exeB8zMrA6t/uS19IEgxwLj46MLGiuBfrVm64s74jIrGB9+\n+CFVVVW8//77+S7FmqC8vJy+fftSWlra6GVaNRQkTQD+GTgiIjbXeushkgeLTCW50Hww/uaoWcGo\nqqqia9eu9O/fn/RZQVbgIoJ169ZRVVXFgAEDdr1AKmfNR+nj/+YChyh5YPh5wM9IenJ8QtKLkn4J\nEBGLSJ5y9SowE/jWru48MrPW8/7779OrVy8HQhsiiV69ejX57C5nZwrp4/92dGsD819N8ijCnJu7\nYi5zls9hbP+xjO43etcLmJkDoQ1qzjFr9WsK+TZ3xVzG3zmeLVu3UFZSxqwzZzkYzMxSRdfNxZzl\nc9iydQtbYytbtm5hzvI5+S7JzBqwbt06Ro4cyciRI9lvv/044IADsvEtW7Y0ah3nnHMOf/nLXxqc\n5+c//zl33dXkGyLr9PnPf54XX3yxRdbV2oruTGFs/7GUlZRlZwpj+4/Nd0lm1oBevXpl/2CvuOIK\nunTpwiWXfPyhchFBRNChQ92fc2+//fZdbudb3/rW7hfbDhTdmcLofqOZdeYs/n3cv7vpyCyH5q6Y\ny4+f/jFzV8zNyfqXLl3K4MGDOe200xgyZAirVq1i8uTJVFZWMmTIEK688sps3u2f3GtqaujevTtT\npkxhxIgRjB49mjVr1gDwgx/8gOuvvz6bf8qUKYwaNYpDDjmEZ599FoBNmzbx1a9+lcGDBzNp0iQq\nKysbfUbw3nvvcdZZZzFs2DAqKip46qmnAHj55Zf5h3/4B0aOHMnw4cNZtmwZGzZs4Oijj2bEiBEM\nHTqU6dOnt+SvrkFFd6YASTA4DMxyp7Wu3b322mvceeedVFYm3fhcc8019OzZk5qaGsaNG8ekSZMY\nPHjwx5ZZv349RxxxBNdccw0XX3wxt912G1OmTNlp3RHB888/z0MPPcSVV17JzJkzuemmm9hvv/24\n//77eemll6ioqGh0rTfeeCN77LEHL7/8MosWLeKYY45hyZIl/OIXv+CSSy7h5JNP5oMPPiAimDFj\nBv379+exxx7Lam4tRXemYGa511rX7j71qU9lgQAwbdo0KioqqKioYPHixbz66qs7LbPnnnty9NFH\nA/CZz3yG5cuX17nuE088cad5nnnmGU455RQARowYwZAhQxpd6zPPPMPpp58OwJAhQ+jTpw9Lly7l\nc5/7HFdddRU//elPWbFiBeXl5QwfPpyZM2cyZcoU/vjHP9KtW7dGb2d3ORTMrMVtv3ZXopKcXrvr\n3LlzNrxkyRJuuOEGnnzySRYuXMiECRPqvEe/rKwsGy4pKaGmpmaneQD22GOPXc7TEs444wwefPBB\n9thjDyZMmMBTTz3FoEGDmDdvHkOGDGHKlCn86Ec/ytn2d+RQMLMWl49rd++++y5du3Zlr732YtWq\nVTz++C4fydJkhx9+OPfddx+QXAuo60ykPmPGjMnublq8eDGrVq3ioIMOYtmyZRx00EFceOGFHHvs\nsSxcuJCVK1fSpUsXzjjjDL773e+yYMGCFt+X+hTlNQUzy73WvnZXUVHB4MGDGThwIJ/4xCc4/PDD\nW3wb3/72tznzzDMZPHhw9qqvaedLX/pS1ufQmDFjuO222/jmN7/JsGHDKC0t5c4776SsrIy7776b\nadOmUVpaSp8+fbjiiit49tlnmTJlCh06dKCsrIxf/vKXLb4v9WnTz2j2Q3bMWsfixYsZNGhQvsvI\nu5qaGmpqaigvL2fJkiUcddRRLFmyhI4dC/fzdV3HrqGH7BTunpiZFZiNGzcyfvx4ampqiAh+9atf\nFXQgNEf72hszsxzq3r078+fPz3cZOeULzWZmlnEomJlZxqFgZmYZh4KZmWUcCmZW8MaNG7fTl9Gu\nv/56zj///AaX69KlCwBvvvkmkyZNqnOesWPHsqtb26+//no2b/7oCcLHHHMM77zzTmNKb9AVV1zB\ntddeu9vraUkOBTMreKeeeir33HPPx6bdc889nHpqXQ943FmfPn12q6fRHUPh0UcfpXv37s1eXyFz\nKJhZwZs0aRKPPPJI9lCd5cuX8+abbzJmzJjsuwMVFRUMGzaMGTNm7LT88uXLGTp0KJB0YX3KKacw\naNAgTjjhBN57771svvPPPz/revvyyy8Hkt5N33zzTcaNG8e4ceMA6N+/P2vXrgVg6tSpDB06lKFD\nh2Zdby9fvpxBgwbxjW98gyFDhnDUUUd9bDu7Utc6N23axJe//OWsO+17770XgClTpjB48GCGDx++\n03MmmsPfUzCzJrnoImjph4qNHAnp/7469ezZk1GjRvHYY48xceJE7rnnHk466SQkUV5ezoMPPshe\ne+3F2rVrOeywwzjuuOPqfT7xzTffTKdOnVi8eDELFy78WPfXV199NT179mTr1q2MHz+ehQsXcsEF\nFzB16lRmz57N3nvv/bF1zZ8/n9tvv53nnnuOiOCzn/0sRxxxBD169GDJkiVMmzaNX//615x00knc\nf//9WS+pDalvncuWLaNPnz488sgjQNKd9rp163jwwQd57bXXkNQiTVo+UzCzNqF2E1LtpqOI4Pvf\n/z7Dhw/nyCOPZOXKlaxevbre9Tz11FPZP+fhw4czfPjw7L377ruPiooKDj30UBYtWrTLDu+eeeYZ\nTjjhBDp37kyXLl048cQTefrppwEYMGAAI0eOBBruorux6xw2bBhPPPEEl112GU8//TTdunWjW7du\nlJeXc9555/HAAw/QqVOnRm2jIT5TMLMmaegTfS5NnDiR73znOyxYsIDNmzfzmc98BoC77rqL6upq\n5s+fT2lpKf3796+zy+xdef3117n22mt54YUX6NGjB2effXaz1rPd9q63Iel+uynNR3X59Kc/zYIF\nC3j00Uf5wQ9+wPjx4/nhD3/I888/z6xZs5g+fTo/+9nPePLJJ3drOz5TMLM2oUuXLowbN45zzz33\nYxeY169fzz777ENpaSmzZ8/mjTfeaHA9X/jCF7j77rsBeOWVV1i4cCGQdL3duXNnunXrxurVq7On\nngF07dqVDRs27LSuMWPG8Pvf/57NmzezadMmHnzwQcaMGbNb+1nfOt988006derE6aefzqWXXsqC\nBQvYuHEj69ev55hjjuG6667jpZde2q1tg88UzKwNOfXUUznhhBM+difSaaedxle+8hWGDRtGZWUl\nAwcObHAd559/Pueccw6DBg1i0KBB2RnHiBEjOPTQQxk4cCD9+vX7WNfbkydPZsKECfTp04fZs2dn\n0ysqKjj77LMZNWoUAF//+tc59NBDG91UBHDVVVdlF5MBqqqq6lzn448/zqWXXkqHDh0oLS3l5ptv\nZsOGDUycOJH333+fiGDq1KmN3m593HW2me2Su85uu5radXbOmo8k3SZpjaRXak3rKekJSUvSnz3S\n6ZJ0o6SlkhZKavzTsM3MrMXk8prCb4EJO0ybAsyKiIOBWek4wNHAwelrMnBzDusyM7N65CwUIuIp\n4O0dJk8E7kiH7wCOrzX9zkj8Ceguaf9c1WZmTdeWm5qLVXOOWWvffbRvRKxKh98C9k2HDwBW1Jqv\nKp22E0mTJc2TNK+6ujp3lZpZpry8nHXr1jkY2pCIYN26dZSXlzdpubzdfRQRIanJf2ERcQtwCyQX\nmlu8MDPbSd++famqqsIfxNqW8vJy+vbt26RlWjsUVkvaPyJWpc1Da9LpK4F+tebrm04zswJQWlrK\ngAED8l2GtYLWbj56CDgrHT4LmFFr+pnpXUiHAetrNTOZmVkrydmZgqRpwFhgb0lVwOXANcB9ks4D\n3gBOSmd/FDgGWApsBs7JVV1mZla/nIVCRNTX0fn4OuYN4Fu5qsXMzBrHfR+ZmVnGoWBmZhmHgpmZ\nZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBm\nZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiY\nmVkmL6Eg6TuSFkl6RdI0SeWSBkh6TtJSSfdKKstHbWZmxazVQ0HSAcAFQGVEDAVKgFOAnwDXRcRB\nwN+B81q7NjOzYpev5qOOwJ6SOgKdgFXAF4Hp6ft3AMfnqTYzs6LV6qEQESuBa4G/kYTBemA+8E5E\n1KSzVQEH1LW8pMmS5kmaV11d3Rolm5kVjXw0H/UAJgIDgD5AZ2BCY5ePiFsiojIiKnv37p2jKs3M\nilM+mo+OBF6PiOqI+BB4ADgc6J42JwH0BVbmoTYzs6KWj1D4G3CYpE6SBIwHXgVmA5PSec4CZuSh\nNjOzopaPawrPkVxQXgC8nNZwC3AZcLGkpUAv4NbWrs3MrNh13PUsLS8iLgcu32HyMmBUHsoxM7OU\nv9FsZmYZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZmWUcCmZm\nlnEomJlZxqFgZmYZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZ\nmWUcCmZmlnEomJlZplGhIOlTkvZIh8dKukBS99yWZmZmra2xZwr3A1slHQTcAvQD7m7uRiV1lzRd\n0muSFksaLamnpCckLUl/9mju+s3MrHkaGwrbIqIGOAG4KSIuBfbfje3eAMyMiIHACGAxMAWYFREH\nA7PScTMza0WNDYUPJZ0KnAU8nE4rbc4GJXUDvgDcChARWyLiHWAicEc62x3A8c1Zv5mZNV9jQ+Ec\nYDRwdUS8LmkA8J/N3OYAoBq4XdKfJf1GUmdg34hYlc7zFrBvM9dvZmbN1KhQiIhXI+KCiJiWtvV3\njYifNHObHYEK4OaIOBTYxA5NRRERQNS1sKTJkuZJmlddXd3MEszMrC6NvftojqS9JPUEFgC/ljS1\nmdusAqoi4rl0fDpJSKyWtH+6vf2BNXUtHBG3RERlRFT27t27mSWYmVldGtt81C0i3gVOBO6MiM8C\nRzZngxHxFrBC0iHppPHAq8BDJNcsSH/OaM76zcys+To2dr700/tJwL+0wHa/DdwlqQxYRnLNogNw\nn6TzgDfSbZmZWStqbChcCTwO/DEiXpD0SWBJczcaES8ClXW8Nb656zQzs93XqFCIiN8Bv6s1vgz4\naq6KMjOz/Gjshea+kh6UtCZ93S+pb66LMzOz1tXYC823k1wI7pO+/judZmZm7UhjQ6F3RNweETXp\n67eA7wc1M2tnGhsK6ySdLqkkfZ0OrMtlYWZm1voaGwrnktwi+hawCpgEnJ2jmszMLE8a283FGxFx\nXET0joh9IuJ4fPeRmVm7sztPXru4xaowM7OCsDuhoBarwszMCsLuhEKdvZiamVnb1eA3miVtoO5/\n/gL2zElFZmaWNw2GQkR0ba1CzMws/3an+cjMzNoZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZmWUc\nCmZmlnEomJlZxqFgZmYZh4KZmWUcCmZmlnEomJlZxqFgZmYZh4KZmWXyFgqSSiT9WdLD6fgASc9J\nWirpXkll+arNzKxY5fNM4UJgca3xnwDXRcRBwN+B8/JSlZlZEctLKEjqC3wZ+E06LuCLwPR0ljuA\n4/NRm5lZMcvXmcL1wD8D29LxXsA7EVGTjlcBB9S1oKTJkuZJmlddXZ37Ss3Mikirh4KkY4E1ETG/\nOctHxC0RURkRlb17927h6szMiluDz2jOkcOB4yQdA5QDewE3AN0ldUzPFvoCK/NQm5lZUWv1M4WI\n+F5E9I2I/sApwJMRcRowG5iUznYWMKO1azMzK3aF9D2Fy4CLJS0lucZwa57rMTMrOvloPspExBxg\nTjq8DBiVz3rMzIpdIZ0pmJlZnjkUzMws41AwM7OMQ8HMzDIOBTMzyzgUzMws41AwM7OMQ8HMzDIO\nBTMzyzgUzMws41AwM7OMQ8HMzDIOBTMzyzgUzMws41AwM7OMQ8HMzDIOBTMzyzgUzMws41AwM7OM\nQ8HMzDIOBTMzyzgUzMws41AwM7OMQ8HMzDIOBTMzy7R6KEjqJ2m2pFclLZJ0YTq9p6QnJC1Jf/Zo\n7drMzIpdPs4UaoDvRsRg4DDgW5IGA1OAWRFxMDArHTczs1bU6qEQEasiYkE6vAFYDBwATATuSGe7\nAzi+tWszMyt2eb2mIKk/cCjwHLBvRKxK33oL2LeeZSZLmidpXnV1davUaWZWLPIWCpK6APcDF0XE\nu7Xfi4gAoq7lIuKWiKiMiMrevXu3QqVmZsUjL6EgqZQkEO6KiAfSyasl7Z++vz+wJh+1mZkVs3zc\nfSTgVmBxREyt9dZDwFnp8FnAjNauzcys2HXMwzYPB84AXpb0Yjrt+8A1wH2SzgPeAE7KQ21mZkWt\n1UMhIp4BVM/b41uzFjMz+zh/o9nMzDIOBTMzyzgUzMws41AwM7NM0YfC3BVz+fHTP2buirn5LsXM\nLO/ycUtqwZi7Yi7j7xzPlq1bKCspY9aZsxjdb3S+yzIzy5uiPlOYs3wOW7ZuYWtsZcvWLcxZPiff\nJZmZ5VVRh8LY/mMpKymjRCWUlZQxtv/YfJdkZpZXRd18NLrfaGadOYs5y+cwtv9YNx2ZWdEr6lCA\nJBgcBmZmiaJuPjIzs49zKJiZWcahYGZmGYeCmZllijIU/vQnOP542Lgx35WYmRWWogyFDz6AGTPg\n0UfzXYmZWWEpylD4/Odh331h+vR8V2JmVliKMhRKSuDEE+GRR2Dz5nxXY2ZWOIoyFAD+6Z+SQHjs\nsXxXYmZWOIo2FMaMgd694Xe/y3clZmaFo2hDoWPHpAnp4YfhvffyXY2ZWWEo2lAAmDQJNm2CmTPz\nXYmZWWEo6lAYOxZ69fJdSGZm2xV1KHTsCCecAA89BEuXQkS+KzIzy6+iDgWAM85ImpAOPhj23hsO\nG/sOR577NDfe/SobNuS7OjOz1qUosI/HkiYANwAlwG8i4pr65q2srIx58+bt9jYXLYJnnoFH5qzm\n4TmridVDITqgDtvo1ffvDB0CR4zqxcCB8OlPJwHStetub9bMLC8kzY+IyrreK6iH7EgqAX4O/CNQ\nBbwg6aGIeDWX2x0yJHm9Pfg2Hh30r2x9rzOqGo2qDmft6qH84flh/GFmTyKULdOp22YOPHAb+/X9\ngA86LWPEp/ahZ+8Pqdr6Z8YMGki3Hh+y8N0/cOQhoyktC/7wxpzscZ/bn/TW1OHR/UYzd8XcZi+f\n6+FCr68t1Vro9bWlWgu9vt2ttaUfElZQZwqSRgNXRMSX0vHvAUTEj+uav6XOFLabu2Iu4+8cz5at\nW5DEttjGtthGBzrQoaYL294eQIe3DyHWHcy2v/eDdwbAOwcSG/aHD7rVv+IOH0Lpe1CyJXl1qAFt\n++gFSEGwDQQCguS4bB+WYL8u+/HWxrfS91RrvtwOb4/CZFh1D0sf1RcNzFcIw4Vea6HX15ZqLfT6\ndqNWKm6jfMwvmHXmrCYHQ5s5UwAOAFbUGq8CPlt7BkmTgckABx54YItuvPYzm3t16sVFMy/6KCBK\nN7Jtn5eIfRYCOxwcAj7cEzbuC5t6w+Z9kp8f7AVbusKWzsn728pgayls6wjRodZLBILYfuABag2H\nQGJb52rotDq7Il47znM3rEbOK7Z1XkuUr+GjSMt1bc0dLvRaC72+tlRrode3G7V2XsWWrVuYs3xO\ni54tFFoo7FJE3ALcAsmZQkuvv/Yzm4ftM2yngCjpUIIQNdtqPj5cvhWVr6Km54r659mN4bKSMq6c\ncP2u68jTcKHX15ZqLfT62lKthV7f7tZaVlKWNSe1lEILhZVAv1rjfdNpeVFXQOS7vbEQ6mir9bWl\nWgu9vrZUa6HXt7u1tvdrCh2BvwLjScLgBeBrEbGorvlb+pqCmVkxaDPXFCKiRtL/BR4nuSX1tvoC\nwczMWl5BhQJARDwK+JloZmZ50CHfBZiZWeFwKJiZWcahYGZmGYeCmZllCuqW1KaSVA280YRF9gbW\n5qicQlaM+12M+wzFud/FuM+we/v9iYjoXdcbbToUmkrSvPruzW3PinG/i3GfoTj3uxj3GXK3324+\nMjOzjEPBzMwyxRYKt+S7gDwpxv0uxn2G4tzvYtxnyNF+F9U1BTMza1ixnSmYmVkDHApmZpYpmlCQ\nNEHSXyQtlTQl3/XkgqR+kmZLelXSIkkXptN7SnpC0pL0Z49815oLkkok/VnSw+n4AEnPpcf8Xkll\n+a6xJUnqLmm6pNckLZY0uhiOtaTvpH/fr0iaJqm8vR1rSbdJWiPplVrT6jy2StyY7vtCSRW7s+2i\nCAVJJcDPgaOBwcCpkgbnt6qcqAG+GxGDgcOAb6X7OQWYFREHA7PS8fboQmBxrfGfANdFxEHA34Hz\n8lJV7twAzIyIgcAIkn1v18da0gHABUBlRAwl6WL/FNrfsf4tMGGHafUd26OBg9PXZODm3dlwUYQC\nMApYGhHLImILcA8wMc81tbiIWBURC9LhDST/JA4g2dc70tnuAI7PT4W5I6kv8GXgN+m4gC8C09NZ\n2tV+S+oGfAG4FSAitkTEOxTBsSbp8n/P9KFcnYBVtLNjHRFPAW/vMLm+YzsRuDMSfwK6S9q/udsu\nllA4AFhRa7wqndZuSeoPHAo8B+wbEavSt94C9s1TWbl0PfDPwLZ0vBfwTkTUpOPt7ZgPAKqB29Mm\ns99I6kw7P9YRsRK4FvgbSRisB+bTvo/1dvUd2xb9/1YsoVBUJHUB7gcuioh3a78XyT3I7eo+ZEnH\nAmsiYn6+a2lFHYEK4OaIOBTYxA5NRe30WPcg+WQ8AOgDdGbnZpZ2L5fHtlhCYSXQr9Z433RauyOp\nlCQQ7oqIB9LJq7efTqY/1+Srvhw5HDhO0nKSpsEvkrS3d0+bGKD9HfMqoCoinkvHp5OERHs/1kcC\nr0dEdUR8CDxAcvzb87Herr5j26L/34olFF4ADk7vUCgjuTD1UJ5ranFpO/qtwOKImFrrrYeAs9Lh\ns4AZrV1bLkXE9yKib0T0J34YeZ0AAAK7SURBVDm2T0bEacBsYFI6W7va74h4C1gh6ZB00njgVdr5\nsSZpNjpMUqf07337frfbY11Lfcf2IeDM9C6kw4D1tZqZmqxovtEs6RiSducS4LaIuDrPJbU4SZ8H\nngZe5qO29e+TXFe4DziQpKvxkyJix4tY7YKkscAlEXGspE+SnDn0BP4MnB4RH+SzvpYkaSTJhfUy\nYBlwDskHvXZ9rCX9G3Ayyd12fwa+TtKG3m6OtaRpwFiS7rFXA5cDv6eOY5uG489ImtE2A+dExLxm\nb7tYQsHMzHatWJqPzMysERwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZnWQtFXSi7VeLdaxnKT+tXu/\nNCskHXc9i1lRei8iRua7CLPW5jMFsyaQtFzSTyW9LOl5SQel0/tLejLtz36WpAPT6ftKelDSS+nr\nc+mqSiT9On0uwP9I2jOd/wIlz8NYKOmePO2mFTGHglnd9tyh+ejkWu+tj4hhJN8ivT6ddhNwR0QM\nB+4Cbkyn3wj8ISJGkPRNtCidfjDw84gYArwDfDWdPgU4NF3P/8nVzpnVx99oNquDpI0R0aWO6cuB\nL0bEsrTzwbciopektcD+EfFhOn1VROwtqRroW7vLhbRb8yfSh6Ug6TKgNCKukjQT2EjSpcHvI2Jj\njnfV7GN8pmDWdFHPcFPU7pdnKx9d3/syyVMCK4AXavX8adYqHApmTXdyrZ9z0+FnSXpoBTiNpGNC\nSB6beD5kz5DuVt9KJXUA+kXEbOAyoBuw09mKWS75U4hZ3faU9GKt8ZkRsf221B6SFpJ82j81nfZt\nkqegXUryRLRz0ukXArdIOo/kjOB8kieG1aUE+K80OATcmD5i06zV+JqCWROk1xQqI2JtvmsxywU3\nH5mZWcZnCmZmlvGZgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZf4/Inb23lvjyIIAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOO65AKMeBgY",
        "colab_type": "text"
      },
      "source": [
        "### **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhHaAcqPeDh4",
        "colab_type": "code",
        "outputId": "c59d56bc-fa96-4225-b191-e40bc62e7b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "predictions = model.predict(tf.cast(training_image_data, tf.float32))\n",
        "\n",
        "image_id = random.randint(0, len(predictions))\n",
        "guess = training_label[np.argmax(predictions[image_id])]\n",
        "print(\"Guess: \" + str(guess) + \": \" + categories[guess])\n",
        "\n",
        "print(\"Actually: \" + categories[training_label[image_id]])\n",
        "\n",
        "# the \"_ = \" prevents the object details to be printed out\n",
        "_ = plt.imshow(training_image_data[image_id].reshape(32, 32))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Guess: 2: dry_cleaning\n",
            "Actually: dry_cleaning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBmYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZxKx5fG5aws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjIOfyXwyR7U",
        "colab_type": "text"
      },
      "source": [
        "### **Saving and exporting to TF Lite file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_HnkQryWC6",
        "colab_type": "code",
        "outputId": "d5111c4d-00e5-499d-d140-57b10062c432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.saved_model.save(model, \".\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\".\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"./assets/laundrysymbol_ai_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "!rm saved_model.pb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}